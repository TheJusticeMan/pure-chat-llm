import { EmptyApiKey, PureChatLLMAPI } from "./types";

const ENDPOINTS: PureChatLLMAPI[] = [
  {
    name: "OpenAI",
    apiKey: EmptyApiKey,
    defaultmodel: "gpt-4.1-nano",
    endpoint: "https://api.openai.com/v1/chat/completions",
    listmodels: "https://api.openai.com/v1/models",
    getapiKey: "https://platform.openai.com/api-keys",
  },
  {
    name: "Gemini",
    apiKey: EmptyApiKey,
    defaultmodel: "gemini-2.0-flash-lite",
    endpoint: "https://generativelanguage.googleapis.com/v1beta/openai/chat/completions",
    listmodels: "https://generativelanguage.googleapis.com/v1beta/openai/models",
    getapiKey: "https://aistudio.google.com/apikey",
  },
  {
    name: "xAI",
    apiKey: EmptyApiKey,
    defaultmodel: "grok-3-mini",
    endpoint: "https://api.x.ai/v1/chat/completions",
    listmodels: "https://api.x.ai/v1/models",
    getapiKey: "https://console.x.ai",
  },
  {
    name: "Anthropic",
    apiKey: EmptyApiKey,
    defaultmodel: "claude-3-7-sonnet-20250219",
    endpoint: "https://api.anthropic.com/v1/messages",
    listmodels: "https://api.anthropic.com/v1/models",
    getapiKey: "https://console.anthropic.com/settings/keys",
  },
  {
    name: "Cohere",
    apiKey: EmptyApiKey,
    defaultmodel: "command",
    endpoint: "https://api.cohere.ai/v1/generate",
    listmodels: "https://api.cohere.ai/v1/models",
    getapiKey: "https://dashboard.cohere.com/api-keys",
  },
  {
    name: "Mistral AI",
    apiKey: EmptyApiKey,
    defaultmodel: "mixtral-8x7b",
    endpoint: "https://api.mistral.ai/v1/chat/completions",
    listmodels: "https://api.mistral.ai/v1/models",
    getapiKey: "https://console.mistral.ai/api-keys",
  },
  {
    name: "DeepSeek",
    apiKey: EmptyApiKey,
    defaultmodel: "deepseek-llm",
    endpoint: "https://api.deepseek.com/v1/chat/completions",
    listmodels: "https://api.deepseek.com/v1/models",
    getapiKey: "https://platform.deepseek.com/api_keys",
  },
];
export const StatSett = {
  splash:
    "# Pure Chat LLM\n\nType `>go` at the end of the file to start a chat session.\n\nFor workflow, bind these commands to hotkeys:\n\n- **`Complete Chat Response`** (Shift + Enter)  \n  *Generate reply and continue chat.*\n\n- **`Generate Title`** (Ctrl + Shift + D)  \n  *Create a note or chat title.*\n\n- **`Edit Selection`** (Ctrl + Shift + S)  \n  *Edit selected text.*\n\n- **`Save Templates`**  \n  *Save SELECTION prompts to `PureChatLLM/templates`.*\n\n- **`Analyze Conversation`**  \n  *Summarize or review chats.*\n\n- **`Open Hotkeys`**  \n  *Customize shortcuts.*\n\nStart exploring and enjoy seamless AI conversations!",
  alloptions: {
    model: "gpt-4o",
    stream: false,
    max_completion_tokens: 100,
    temperature: 1,
    top_p: 1,
    n: 1,
    stop: null,
    logit_bias: null,
    metadata: {},
    modalities: ["text"],
    tool_choice: "none",
    tools: [],
    web_search_options: {},
    user: "user-1234",
  },
  version: "1.2.1",
  ENDPOINTS: ENDPOINTS,
  chatParser: [
    {
      name: "SimpleMarkdownHeader",
      description: "Simple markdown header parser",
      SplitMessages: /^# role: (?=system|user|assistant|developer)/im,
      getRole: /^(system|user|assistant|developer)[^\n]+\n/i,
      rolePlacement: "# role: {role}",
      isChat: /^# role: (system|user|assistant|developer)/i,
    },
    {
      name: "NoteMarkdownHeader",
      description: "Note markdown header parser",
      SplitMessages: /^\n> \[!note\] \w+\n> # role: (?=system|user|assistant|developer)/im,
      getRole: /^(system|user|assistant|developer)[^\n]+\n/i,
      rolePlacement: "\n> [!note] {role}\n> # role: {role}\n",
      isChat: /^> \[!note\] \w+\n> # role: (system|user|assistant|developer)/i,
    },
  ],
};
